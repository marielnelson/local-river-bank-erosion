{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import shapely\n",
    "from scipy.spatial import cKDTree\n",
    "from shapely.geometry import LineString, Polygon, MultiPolygon, Point\n",
    "import alphashape\n",
    "import sys\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "mpl.rcParams.update({\n",
    "    'font.sans-serif': 'Arial',\n",
    "    'savefig.dpi': 600,\n",
    "    'figure.dpi': 150,\n",
    "    'font.size': 7,\n",
    "    'figure.figsize': [4, 2.5],\n",
    "    'axes.labelpad': 5,\n",
    "    'axes.linewidth': 0.5,\n",
    "    'xtick.major.width': 0.5,\n",
    "    'ytick.major.width': 0.5,\n",
    "    'axes.titlesize': 'medium',\n",
    "    'legend.fontsize': 'medium',\n",
    "    'text.usetex': False,\n",
    "    'mathtext.fontset': 'stixsans',\n",
    "    'mathtext.default': 'it',\n",
    "})\n",
    "\n",
    "pd.options.display.max_columns = 50\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "centimeters = 1 / 2.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.load_data import load_transects\n",
    "\n",
    "centerline = pd.read_csv('1_input-data/centerline-points-with-idx.csv')\n",
    "all_transects = load_transects('1_input-data/join_*-transect-25m.csv')\n",
    "all_transects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "ones that look a bit weird\n",
    "\n",
    "22\n",
    "51\n",
    "59"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "#### clean and prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transects['survey_date'] = pd.to_datetime(all_transects['survey_date'], format='%Y-%m-%d', errors='coerce')\n",
    "all_transects = all_transects.sort_values(['survey_date', 'transect_idx', 'z']).reset_index(drop=True)\n",
    "\n",
    "centerline = centerline.rename(columns={'x': 'centerline_x', 'y': 'centerline_y'})\n",
    "all_transects = all_transects.merge(centerline, on=['transect_idx'], how='left')\n",
    "\n",
    "# calculate projected distance along transect\n",
    "\n",
    "all_transects['linear_distance'] = np.sqrt(\n",
    "    (all_transects['x'] - all_transects['centerline_x'])**2 +\n",
    "    (all_transects['y'] - all_transects['centerline_y'])**2\n",
    ")\n",
    "\n",
    "all_transects['d_along_transect'] = np.sqrt(all_transects['linear_distance']**2 - all_transects['d_transect']**2)\n",
    "\n",
    "d_along_transect_min = (\n",
    "    all_transects\n",
    "    .groupby('transect_idx')['d_along_transect']\n",
    "    .transform('min')\n",
    ")\n",
    "\n",
    "all_transects['d_along_transect_adj'] = all_transects['d_along_transect'] - d_along_transect_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove transects\n",
    "\n",
    "all_transects = all_transects[~all_transects['transect_idx'].isin([1, 2])].copy() # beginning bend 1 before bank edge mapping starts\n",
    "all_transects = all_transects[~all_transects['transect_idx'].isin([25, 33])].copy() # bend 1 floodplain channels\n",
    "all_transects = all_transects[~all_transects['transect_idx'].isin([38, 39])].copy() # bend 1 culvert and pile of tires\n",
    "all_transects = all_transects[~all_transects['transect_idx'].isin([64, 65, 66])].copy() # bend 1 sunken boat\n",
    "all_transects = all_transects[~all_transects['transect_idx'].isin([79, 80, 81, 82])].copy() # last transects bend 1 actually on point bar\n",
    "\n",
    "# set max distance from transect to use points from\n",
    "\n",
    "max_transect_width = 1\n",
    "all_transects = all_transects[all_transects['d_transect'] <= max_transect_width / 2].copy()\n",
    "\n",
    "# remove points over max elevation that likely are misclassified trees\n",
    "\n",
    "all_transects = all_transects[all_transects['z'] < 11.5].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transects[all_transects['bend'] == 2]['transect_idx'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transects[(all_transects['z'] > 11.5)  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_df(df, transect_idx, date):\n",
    "    date = pd.to_datetime(date)\n",
    "    return df[(df['transect_idx'] == transect_idx) & (df['survey_date'] == date)]\n",
    "\n",
    "STYLE_ORIG = dict(marker='.', linestyle='none', alpha=0.2, markersize=2)\n",
    "STYLE_FILT = dict(marker='.', linestyle='none', alpha=1, markersize=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### apply box median filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "#### apply for chosen dates and transects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_median_coords(df, x, z, dx, dz):\n",
    "    coords = df[[x, z]].to_numpy()\n",
    "    tree = cKDTree(coords)\n",
    "    r = max(dx, dz)\n",
    "    x_meds, z_meds = [], []\n",
    "\n",
    "    for xi, zi in coords:\n",
    "        x0, x1 = xi - dx / 2, xi + dx / 2\n",
    "        z0, z1 = zi - dz / 2, zi + dz / 2\n",
    "        idx = [j for j in tree.query_ball_point([xi, zi], r)\n",
    "               if x0 <= coords[j, 0] <= x1 and z0 <= coords[j, 1] <= z1]\n",
    "\n",
    "        if idx:\n",
    "            x_meds.append(np.median(df.iloc[idx][x]))\n",
    "            z_meds.append(np.median(df.iloc[idx][z]))\n",
    "        else:\n",
    "            x_meds.append(xi)\n",
    "            z_meds.append(zi)\n",
    "\n",
    "    f = df.assign(x_box_median=x_meds, z_box_median=z_meds)\n",
    "\n",
    "    # # re-add original coords of min z and max x points to try to keep existing range\n",
    "    # min_z_idx = f[f[z] == f[z].min()].index[0]\n",
    "    # max_x_idx = f[f[x] == f[x].max()].index[0]\n",
    "    # f.loc[min_z_idx, ['x_box_median', 'z_box_median']] = f.loc[min_z_idx, [x, z]].values\n",
    "    # f.loc[max_x_idx, ['x_box_median', 'z_box_median']] = f.loc[max_x_idx, [x, z]].values\n",
    "\n",
    "    # # re-add original coords of point with max x and max z only if it is the maximum overall\n",
    "    # max_both_idx = f[(f[x] == f[x].max()) & (f[z] == f[z].max())].index\n",
    "    # max_both_idx = max_both_idx[0] if len(max_both_idx) > 0 else None\n",
    "\n",
    "    if (f[x].max() > f['x_box_median'].max()) and (f[z].max() > f['z_box_median'].max()):\n",
    "        max_both_idx = f[(f[x] == f[x].max()) & (f[z] == f[z].max())].index\n",
    "        max_both_idx = max_both_idx[0] if len(max_both_idx) > 0 else None\n",
    "    else:\n",
    "        max_both_idx = None\n",
    "\n",
    "    if max_both_idx is not None:\n",
    "        f.loc[max_both_idx, ['x_box_median', 'z_box_median']] = f.loc[max_both_idx, [x, z]].values\n",
    "        \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a transect index and dates to plot with variable box size\n",
    "\n",
    "def box_filter_and_plot_transect(df, x, z, transect_idx, dates, box_sizes=[(0.5, 0.5), (1, 1)]):\n",
    "    fig, ax = plt.subplots(dpi=150)\n",
    "\n",
    "    for date in dates:\n",
    "        subset = subset_df(df, transect_idx, date)\n",
    "        date = pd.to_datetime(date)\n",
    "\n",
    "        ax.plot(subset[x], subset[z], label=f'{date.date()}', **{**STYLE_ORIG, 'markersize': 1})\n",
    "\n",
    "        for dx, dz in box_sizes:\n",
    "            f = box_median_coords(subset, x=x, z=z, dx=dx, dz=dz)\n",
    "            f = f.dropna(subset=['x_box_median', 'z_box_median'])\n",
    "\n",
    "            label = f'{date.date()} filtered ({dx}×{dz} m)'\n",
    "            ax.plot(f['x_box_median'], f['z_box_median'], label=label, **{**STYLE_FILT, 'markersize': 2, 'mew':0})\n",
    "\n",
    "    ax.set(xlabel='projected distance along centerline (m)', ylabel='z (m)',\n",
    "           title=f'transect {transect_idx} box median filter')\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1.02, 1), borderaxespad=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "transect_ids = np.sort(all_transects['transect_idx'].unique())[3::100]\n",
    "dates = ['2022-04-15', '2024-09-06']\n",
    "\n",
    "for tid in transect_ids:\n",
    "    box_filter_and_plot_transect(all_transects, 'd_along_transect_adj', 'z', transect_idx=tid, dates=dates, box_sizes=[ (0.5, 3), (1, 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double median filter could be nice but not working at the moment\n",
    "\n",
    "# transect_ids = np.sort(all_transects['transect_idx'].unique())[3::100]\n",
    "# dates = ['2022-04-15', '2024-09-06']\n",
    "# median_box_1 = [(0.5, 3), (1, 3)]\n",
    "# median_box_2 = [(0.5, 1), (1, 1)]\n",
    "\n",
    "# all_filtered = {}\n",
    "\n",
    "# for tid in transect_ids:\n",
    "#     all_filtered[tid] = box_filter_and_plot_transect(all_transects, 'd_along_transect_adj', 'z', transect_idx=tid, dates=dates, box_sizes=median_box_1)\n",
    "\n",
    "# for date in dates:\n",
    "#     for box_1_size in median_box_1:\n",
    "#         filtered_df = all_filtered[tid][pd.to_datetime(date)][box_1_size]\n",
    "#         for box_2_size in median_box_2:\n",
    "#             twice_filtered = box_median_coords(filtered_df, x='x_box_median', z='z_box_median', dx=box_2_size[0], dz=box_2_size[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "#### apply for all dates and transects and export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "would be great to make this check the folder first and only apply filter to those that are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box_filtered_dfs = []\n",
    "# dx, dz = 1, 3  # meters\n",
    "\n",
    "# for date in pd.to_datetime(all_transects['survey_date'].unique()):\n",
    "#     transects = all_transects[all_transects['survey_date'] == date]['transect_idx'].unique()\n",
    "#     n = len(transects)\n",
    "\n",
    "#     print(f'📅 {date.date()} | 0/{n} starting...', end='\\r')\n",
    "\n",
    "#     for i, t_id in enumerate(transects, 1):\n",
    "#         print(f'📅 {date.date()} transect {i}/{n} filtered'.ljust(60), end='\\r')\n",
    "\n",
    "#         subset = all_transects[(all_transects['survey_date'] == date) &(all_transects['transect_idx'] == t_id)]\n",
    "#         f = box_median_coords(subset, x='d_along_transect_adj', z='z', dx=dx, dz=dz)\n",
    "#         f['filter_dx'], f['filter_dz'] = dx, dz\n",
    "#         box_filtered_dfs.append(f)\n",
    "\n",
    "#     print(f'✅ {date.date()} | {n}/{n} done'.ljust(60))\n",
    "\n",
    "# # export\n",
    "\n",
    "# df_filtered_all = pd.concat(box_filtered_dfs, ignore_index=True)\n",
    "# df_filtered_all.to_parquet('data/transects_box_filtered.parquet', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "#### import median filtered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transects_filt = pd.read_parquet('data/transects_box_filtered.parquet')\n",
    "all_transects_filt['bend'] = (all_transects_filt['transect_idx'] > 80).astype(int) + 1\n",
    "all_transects_filt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "#### plot chosen dates from all data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box_filtered_transects(df, x, z, transect_idx, dates):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    for date in dates:\n",
    "        date = pd.to_datetime(date)\n",
    "        subset = subset_df(df, transect_idx, date)\n",
    "\n",
    "        ax.plot(subset[x], subset[z], label=f'{date.date()}', **STYLE_ORIG)\n",
    "\n",
    "        f = subset.dropna(subset=[x, z])\n",
    "        dx_vals = f['filter_dx'].unique()\n",
    "        dz_vals = f['filter_dz'].unique()\n",
    "\n",
    "        dx, dz = dx_vals[0], dz_vals[0]\n",
    "        label = f'{date.date()} filtered ({dx}×{dz} m)'\n",
    "        ax.plot(f[x], f[z], label=label, **STYLE_FILT)\n",
    "\n",
    "    ax.set(xlabel='projected distance along centerline (m)', ylabel='z (m)',\n",
    "           title=f'transect {transect_idx} box median filter')\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1.02, 1), borderaxespad=0)\n",
    "    ax.set_xlim(-1, 25)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_transect_idxs = np.sort(all_transects_filt['transect_idx'].unique())[94::100]\n",
    "sorted_transect_idxs = [105]\n",
    "dates = ['2022-09-21', '2023-01-07']\n",
    "dates = ['2022-04-15', '2022-06-17', '2022-09-21', '2023-01-07', '2023-12-08']\n",
    "dates = ['2024-02-27', '2024-09-06', '2025-04-04', '2025-08-22']\n",
    "\n",
    "for idx in sorted_transect_idxs:\n",
    "    plot_box_filtered_transects(all_transects_filt, 'x_box_median', 'z_box_median', transect_idx=idx, dates=dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### add zmax points per transect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old version, adds points to overall zmax regardless of survey timing\n",
    "\n",
    "# def add_zmax_points_per_transect(df, x, z, transect_idx):\n",
    "#     transect_data = df[df['transect_idx'] == transect_idx]\n",
    "#     overall_zmax = transect_data[z].max()\n",
    "\n",
    "#     new_points = []\n",
    "#     for date in transect_data['survey_date'].dropna().unique():\n",
    "#         date_data = transect_data[transect_data['survey_date'] == pd.to_datetime(date)]\n",
    "\n",
    "#         if date_data[z].max() < overall_zmax:\n",
    "#             xmax_idx = date_data[x].idxmax()\n",
    "\n",
    "#             # add offset to z for piecewise sorting\n",
    "#             new_point = {\n",
    "#                 x: date_data.loc[xmax_idx, x],\n",
    "#                 z: overall_zmax + 0.01,\n",
    "#                 'transect_idx': transect_idx,\n",
    "#                 'survey_date': date,\n",
    "#                 'added_zmax': True,\n",
    "#                 'zmax_height': overall_zmax - date_data[z].max()\n",
    "#             }\n",
    "#             new_points.append(new_point)\n",
    "            \n",
    "#     return pd.DataFrame(new_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_zmax_points_per_transect(df, x, z, transect_idx):\n",
    "    transect_data = df[df['transect_idx'] == transect_idx]\n",
    "    \n",
    "    # sort dates chronologically to establish survey order\n",
    "    dates = sorted(transect_data['survey_date'].dropna().unique())\n",
    "    \n",
    "    new_points = []\n",
    "    \n",
    "    for i, date in enumerate(dates):\n",
    "        date_data = transect_data[transect_data['survey_date'] == pd.to_datetime(date)]\n",
    "        \n",
    "        # first survey: use original logic (no previous surveys exist)\n",
    "        if i == 0:\n",
    "            overall_zmax = transect_data[z].max()\n",
    "            if date_data[z].max() < overall_zmax:\n",
    "                xmax_idx = date_data[x].idxmax()\n",
    "                new_point = {\n",
    "                    x: date_data.loc[xmax_idx, x],\n",
    "                    z: overall_zmax + 0.01,\n",
    "                    'transect_idx': transect_idx,\n",
    "                    'survey_date': date,\n",
    "                    'added_upper_z': 'overall',\n",
    "                    'added_z_height': overall_zmax - date_data[z].max(),\n",
    "                    'added_from_date': None\n",
    "                }\n",
    "                new_points.append(new_point)\n",
    "        else:\n",
    "            # for subsequent surveys: check if previous surveys have \n",
    "            # points extending further and higher than current z.max() point\n",
    "            zmax_idx = date_data[z].idxmax()\n",
    "            current_zmax = date_data.loc[zmax_idx, z]\n",
    "            current_x_at_zmax = date_data.loc[zmax_idx, x]\n",
    "            \n",
    "            # search previous surveys (most recent first) for suitable points\n",
    "            suitable_points = None\n",
    "            \n",
    "            for prev_date in reversed(dates[:i]):\n",
    "                prev_date_data = transect_data[transect_data['survey_date'] == pd.to_datetime(prev_date)]\n",
    "                \n",
    "                # find points in previous survey with both higher x and higher z\n",
    "                # than the current survey's highest elevation point\n",
    "                candidate_points = prev_date_data[\n",
    "                    (prev_date_data[x] > current_x_at_zmax) & \n",
    "                    (prev_date_data[z] > current_zmax)\n",
    "                ]\n",
    "                \n",
    "                if not candidate_points.empty:\n",
    "                    suitable_points = candidate_points\n",
    "                    break  # use most recent survey that satisfies conditions\n",
    "            \n",
    "            # add qualifying points from previous survey, labeled with current date\n",
    "            if suitable_points is not None:\n",
    "                for _, row in suitable_points.iterrows():\n",
    "                    new_point = {\n",
    "                        x: row[x],\n",
    "                        z: row[z],\n",
    "                        'transect_idx': transect_idx,\n",
    "                        'survey_date': date,  # label with current survey date\n",
    "                        'added_upper_z': 'previous',\n",
    "                        'added_z_height': row[z] - current_zmax,\n",
    "                        'added_from_date': row['survey_date']\n",
    "                    }\n",
    "                    new_points.append(new_point)\n",
    "            else:\n",
    "                # fallback: use original logic if no suitable previous points found\n",
    "                overall_zmax = transect_data[z].max()\n",
    "                if date_data[z].max() < overall_zmax:\n",
    "                    xmax_idx = date_data[x].idxmax()\n",
    "                    new_point = {\n",
    "                        x: date_data.loc[xmax_idx, x],\n",
    "                        z: overall_zmax + 0.01,\n",
    "                        'transect_idx': transect_idx,\n",
    "                        'survey_date': date,\n",
    "                        'added_upper_z': 'overall',\n",
    "                        'added_z_height': overall_zmax - date_data[z].max(),\n",
    "                        'added_from_date': None\n",
    "                    }\n",
    "                    new_points.append(new_point)\n",
    "    \n",
    "    return pd.DataFrame(new_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_new_points = []\n",
    "df = all_transects_filt\n",
    "\n",
    "for transect in df.transect_idx.unique():\n",
    "    new_points = add_zmax_points_per_transect(df, 'x_box_median', 'z_box_median', transect)\n",
    "    all_new_points.append(new_points)\n",
    "\n",
    "all_transects_filt_add_max = pd.concat([df] + all_new_points, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transects_filt_add_max.added_z_height.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 2.5))\n",
    "sns.boxplot(all_transects_filt_add_max, x='transect_idx', y='added_z_height', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### piecewise interpolation in z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def piecewise_sample_transect(df, x, z, transect_idx, date, dz=0.05):\n",
    "    \"\"\"\n",
    "    linearly interpolate x as a function of z for a single transect and date.\n",
    "    returns sampled points at even spacing in z, clipped to observed z range.\n",
    "    \"\"\"\n",
    "    date = pd.to_datetime(date)\n",
    "    subset = df[(df['transect_idx'] == transect_idx) & (df['survey_date'] == date)].dropna(subset=[x, z])\n",
    "    subset = subset.sort_values(by=z)\n",
    "\n",
    "    z_vals = subset[z].values\n",
    "    x_vals = subset[x].values\n",
    "    window_size = 0.5 # meters\n",
    "\n",
    "    # remove outliers with big jumps in x using spatial window\n",
    "    rolling_std = []\n",
    "    for i, z_point in enumerate(z_vals):\n",
    "        mask = np.abs(z_vals - z_point) <= window_size / 2\n",
    "        n_points = np.sum(mask)\n",
    "        if n_points <= 1:\n",
    "            rolling_std.append(0)  # keep points with ≤2 neighbors\n",
    "        else:\n",
    "            rolling_std.append(np.std(x_vals[mask]))\n",
    "\n",
    "    subset = subset.copy()\n",
    "    subset['rolling_std'] = rolling_std\n",
    "    \n",
    "    rolling_std = np.array(rolling_std)\n",
    "    mask = rolling_std <= 0.5\n",
    "    subset_filtered = subset[mask].copy()\n",
    "\n",
    "    z_vals_filtered = subset_filtered[z].values\n",
    "    x_vals_filtered = subset_filtered[x].values\n",
    "\n",
    "    z_piecewise = np.arange(z_vals_filtered.min(), z_vals_filtered.max() + dz, dz)\n",
    "    x_piecewise = np.interp(z_piecewise, z_vals_filtered, x_vals_filtered)\n",
    "\n",
    "    sampled_transect = pd.DataFrame({\n",
    "        'transect_idx': transect_idx,\n",
    "        'survey_date': date,\n",
    "        'z_piecewise': z_piecewise,\n",
    "        'x_piecewise': np.round(x_piecewise, 3),\n",
    "        'dz_piecewise': dz\n",
    "    })\n",
    "    return sampled_transect, subset[[z, x, 'rolling_std']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "#### apply to all data and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_piecewise_samples = []\n",
    "dz_piecewise = 0.05 # meters\n",
    "df = all_transects_filt_add_max\n",
    "date_list = pd.to_datetime(df['survey_date'].unique())\n",
    "# date_list = [pd.to_datetime('2022-09-21')]\n",
    "\n",
    "for date in date_list:\n",
    "    transects = df[df['survey_date'] == date]['transect_idx'].unique()\n",
    "    # transects = [22]\n",
    "\n",
    "    for t_id in transects:\n",
    "        sampled, rolling_std_df = piecewise_sample_transect(df, 'x_box_median', 'z_box_median', t_id, date, dz=dz_piecewise)\n",
    "        if sampled is not None:\n",
    "            all_piecewise_samples.append(sampled)\n",
    "\n",
    "all_transects_sampled = pd.concat(all_piecewise_samples, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_std_df.plot('x_box_median', 'z_box_median', 'scatter', c='rolling_std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_transects_sampled = all_transects_sampled[all_transects_sampled['transect_idx']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_piecewise_sampled_vs_box_filtered_profile(df_box_filtered, df_piecewise_sampled, transect_idx, dates):\n",
    "    \"\"\"\n",
    "    plot filtered (x_box_median, z_box_median) and interpolated (x_piecewise, z_piecewise) for a transect and date\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(7 * centimeters, 4 * centimeters))\n",
    "    dates = pd.to_datetime(dates)\n",
    "    colors = plt.cm.twilight_shifted(np.linspace(0, 0.9, len(dates)))\n",
    "\n",
    "    for i, date in enumerate(dates):    \n",
    "        f = df_box_filtered[\n",
    "            (df_box_filtered['transect_idx'] == transect_idx) &\n",
    "            (df_box_filtered['survey_date'] == date)\n",
    "        ].dropna(subset=['x_box_median', 'z_box_median'])\n",
    "\n",
    "        s = df_piecewise_sampled[(df_piecewise_sampled['transect_idx'] == transect_idx) & (df_piecewise_sampled['survey_date'] == date)]\n",
    "        \n",
    "        base_color = np.minimum(colors[i] + 0.1, 1.0)\n",
    "        dark_color = base_color * 0.7\n",
    "\n",
    "        ax.plot(f['x_box_median'], f['z_box_median'], '.', alpha=0.15, markersize=6, color=base_color, mew=0)\n",
    "        # ax.plot(s['x_piecewise'], s['z_piecewise'], '.', markersize=2, label='sampled (dz={:.2f})'.format(s['dz_piecewise'].iloc[0]))\n",
    "        ax.plot(s['x_piecewise'], s['z_piecewise'], '.', markersize=2, label=date.strftime('%Y-%m-%d'), color=dark_color, mew=0, alpha=1)\n",
    "\n",
    "    ax.set(xlabel='x (m)', ylabel='z (m)', title=f'transect {transect_idx}', \n",
    "        # xlim=(-1, 22), ylim=(4, 13)\n",
    "        )\n",
    "    # ax.legend(loc='upper left', bbox_to_anchor=(1.02, 1), markerscale=3)\n",
    "    ax.tick_params(axis='both', pad=3)\n",
    "\n",
    "    os.makedirs('f2-alphashapes', exist_ok=True)\n",
    "    fig.savefig(f'f2-alphashapes/transect_{transect_idx}.pdf', bbox_inches='tight', pad_inches=0.05)\n",
    "\n",
    "    plt.show()\n",
    "    # plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "working but plots are updated with most recent changes and takes ~ 2 min to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.to_datetime(all_transects_filt_add_max['survey_date'].unique())[::]\n",
    "# # dates = [pd.to_datetime('2022-09-21')]\n",
    "# transect_ids = all_transects_filt_add_max['transect_idx'].unique()[::]\n",
    "transect_ids = [21, 60, 96, ]\n",
    "\n",
    "for t_id in transect_ids:\n",
    "    plot_piecewise_sampled_vs_box_filtered_profile(all_transects_filt_add_max, all_transects_sampled, t_id, dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_piecewise_sampled_vs_box_filtered_profile_3transects(df_box_filtered, df_piecewise_sampled, transect_idxs, dates):\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(19 * centimeters, 4 * centimeters), gridspec_kw={'wspace': 0.05})\n",
    "    dates = pd.to_datetime(dates)\n",
    "    colors = plt.cm.twilight_shifted(np.linspace(0, 0.9, len(dates)))\n",
    "    \n",
    "    all_x_vals = []\n",
    "    all_z_vals = []\n",
    "    \n",
    "    for transect_idx in transect_idxs:\n",
    "        for date in dates:\n",
    "            f = df_box_filtered[\n",
    "                (df_box_filtered['transect_idx'] == transect_idx) &\n",
    "                (df_box_filtered['survey_date'] == date)\n",
    "            ].dropna(subset=['x_box_median', 'z_box_median'])\n",
    "            \n",
    "            s = df_piecewise_sampled[\n",
    "                (df_piecewise_sampled['transect_idx'] == transect_idx) & \n",
    "                (df_piecewise_sampled['survey_date'] == date)\n",
    "            ]\n",
    "            \n",
    "            if not f.empty:\n",
    "                all_x_vals.extend(f['x_box_median'])\n",
    "                all_z_vals.extend(f['z_box_median'])\n",
    "            if not s.empty:\n",
    "                all_x_vals.extend(s['x_piecewise'])\n",
    "                all_z_vals.extend(s['z_piecewise'])\n",
    "    \n",
    "    x_padding = (max(all_x_vals) - min(all_x_vals)) * 0.05\n",
    "    z_padding = (max(all_z_vals) - min(all_z_vals)) * 0.05\n",
    "    xlim = (min(all_x_vals) - x_padding, max(all_x_vals) + x_padding)\n",
    "    zlim = (min(all_z_vals) - z_padding, max(all_z_vals) + z_padding)\n",
    "    \n",
    "    for plot_idx, transect_idx in enumerate(transect_idxs):\n",
    "        ax = axes[plot_idx]\n",
    "        \n",
    "        for i, date in enumerate(dates):    \n",
    "            f = df_box_filtered[\n",
    "                (df_box_filtered['transect_idx'] == transect_idx) &\n",
    "                (df_box_filtered['survey_date'] == date)\n",
    "            ].dropna(subset=['x_box_median', 'z_box_median'])\n",
    "\n",
    "            s = df_piecewise_sampled[\n",
    "                (df_piecewise_sampled['transect_idx'] == transect_idx) & \n",
    "                (df_piecewise_sampled['survey_date'] == date)\n",
    "            ]\n",
    "            \n",
    "            base_color = np.minimum(colors[i] + 0.1, 1.0)\n",
    "            dark_color = base_color * 0.7\n",
    "\n",
    "            if not f.empty:\n",
    "                ax.plot(f['x_box_median'], f['z_box_median'], '.', alpha=0.1, markersize=6, color=base_color, mew=0, rasterized=True)\n",
    "            if not s.empty:\n",
    "                label = date.strftime('%Y-%m-%d') if plot_idx == 0 else None  # Only label first subplot\n",
    "                ax.plot(s['x_piecewise'], s['z_piecewise'], '.', markersize=2, label=label, color=dark_color, mew=0, alpha=1, rasterized=True)\n",
    "\n",
    "        ax.set_xlabel('x (m)')\n",
    "        ax.set_ylabel('z (m)' if plot_idx == 0 else '')  # Only label y-axis for first subplot\n",
    "        ax.set_title(f'transect {transect_idx}')\n",
    "        ax.set_xlim(xlim)\n",
    "        ax.set_ylim(zlim)\n",
    "        ax.tick_params(axis='both', pad=3)\n",
    "        # ax.set_xticks([1, 4, 7, 9])\n",
    "        # for ax in axes:\n",
    "        #     ax.grid(axis='y', linestyle='-', alpha=0.5)\n",
    "\n",
    "        if plot_idx > 0:\n",
    "            ax.set_yticks([])\n",
    "            # ax.spines['left'].set_visible(False)\n",
    "            # ax.spines['right'].set_visible(False)\n",
    "        if plot_idx != 1:\n",
    "            ax.set_xlabel('')\n",
    "    \n",
    "    axes[0].legend(loc='upper left', bbox_to_anchor=(3.15, 1.05), markerscale=3, handletextpad=0.2)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    os.makedirs('f2-alphashapes', exist_ok=True)\n",
    "    transect_str = '_'.join(map(str, transect_idxs))\n",
    "    fig.savefig(f'f2-alphashapes/transects_{transect_str}.pdf', bbox_inches='tight', pad_inches=0.05, dpi=600)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_piecewise_sampled_vs_box_filtered_profile_3transects(\n",
    "    all_transects_filt_add_max, \n",
    "    all_transects_sampled, \n",
    "    [21, 60, 96], \n",
    "    dates\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "### clip data with z values below the highest river stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_min_max = (\n",
    "    all_transects_sampled\n",
    "    .groupby(['transect_idx', 'survey_date'])['z_piecewise'].min()\n",
    "    .groupby('transect_idx').max()\n",
    "    .rename('z_min_max')\n",
    "    .reset_index()\n",
    ")\n",
    "all_transects_sampled_clipped = all_transects_sampled.merge(z_min_max, on='transect_idx')\n",
    "all_transects_sampled_clipped = all_transects_sampled_clipped[all_transects_sampled_clipped['z_piecewise'] >= all_transects_sampled_clipped['z_min_max']].copy()\n",
    "all_transects_sampled_clipped = all_transects_sampled_clipped.drop(columns='z_min_max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transects_sampled_clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sampled_profiles_by_date(df, transect_idx, dates):\n",
    "    \"\"\"\n",
    "    plot x_piecewise vs z_piecewise for one transect and one or more survey dates\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # handle single date input\n",
    "    dates = pd.to_datetime(dates) if isinstance(dates, (str, pd.Timestamp)) else pd.to_datetime(dates)\n",
    "\n",
    "    for date in dates:\n",
    "        subset = subset_df(df, transect_idx, date)\n",
    "        if not subset.empty:\n",
    "            ax.plot(subset['x_piecewise'], subset['z_piecewise'], label=str(date.date()), linestyle='-', marker='.')\n",
    "\n",
    "    ax.set(xlabel='x (m)', ylabel='z (m)', title=f'transect {transect_idx}')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transects_sampled_clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sampled_profiles_by_date(all_transects_sampled_clipped, transect_idx=10, dates=['2022-04-15', '2025-08-22'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "### make bounding points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for two transects, make lines connecting the xmin points and the zmax points and sample points along those lines\n",
    "\n",
    "# def create_bounding_points(df, transect_idx, date1, date2, x='x_piecewise', z='z_piecewise', spacing=0.1):\n",
    "#     \"\"\"\n",
    "#     sample lines connecting xmin and zmax points between two surveys with fixed spacing\n",
    "#     \"\"\"\n",
    "#     d1, d2 = pd.to_datetime([date1, date2])\n",
    "#     f = df[(df['transect_idx'] == transect_idx) & (df['survey_date'].isin([d1, d2]))]\n",
    "#     f1, f2 = f[f['survey_date'] == d1], f[f['survey_date'] == d2]\n",
    "\n",
    "#     def get_endpoints(kind):\n",
    "#         i = x if kind == 'xmin' else z\n",
    "#         return f1.loc[f1[i].idxmin() if kind == 'xmin' else f1[i].idxmax()][[x, z]].values, \\\n",
    "#                f2.loc[f2[i].idxmin() if kind == 'xmin' else f2[i].idxmax()][[x, z]].values\n",
    "\n",
    "#     def sample_line(p1, p2):\n",
    "#         dist = np.linalg.norm(p2 - p1)\n",
    "#         t = np.arange(0, 1 + spacing / dist, spacing / dist)\n",
    "#         return np.column_stack([p1[0] + t * (p2[0] - p1[0]), p1[1] + t * (p2[1] - p1[1])])\n",
    "\n",
    "#     xmin_line = sample_line(*get_endpoints('xmin'))\n",
    "#     zmax_line = sample_line(*get_endpoints('zmax'))\n",
    "\n",
    "#     out = pd.DataFrame(np.vstack([xmin_line, zmax_line]), columns=[x, z])\n",
    "#     out['transect_idx'] = transect_idx\n",
    "#     out['connector'] = ['xmin'] * len(xmin_line) + ['zmax'] * len(zmax_line)\n",
    "#     out['survey_date_1'], out['survey_date_2'] = d1, d2\n",
    "\n",
    "#     return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "#### calculate bounding points for one transect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bounding_points(df, x, z, transect_idx, date1, date2, spacing=0.1):\n",
    "    d1, d2 = pd.to_datetime([date1, date2])\n",
    "    f = df[(df['transect_idx'] == transect_idx) & (df['survey_date'].isin([d1, d2]))]\n",
    "    f1, f2 = f[f['survey_date'] == d1], f[f['survey_date'] == d2]\n",
    "\n",
    "    def get_endpoints(kind):\n",
    "        if kind == 'xmin':\n",
    "            p1 = f1.loc[f1[x].idxmin()][[x, z]].values\n",
    "            p2 = f2.loc[f2[x].idxmin()][[x, z]].values\n",
    "        elif kind == 'zmax':\n",
    "            p1 = f1.loc[f1[z].idxmax()][[x, z]].values\n",
    "            p2 = f2.loc[f2[z].idxmax()][[x, z]].values\n",
    "        return p1, p2\n",
    "\n",
    "    def sample_line(p1, p2):\n",
    "        dist = np.linalg.norm(p2 - p1)\n",
    "        n_points = int(dist / spacing) + 1\n",
    "        t = np.linspace(0, 1, n_points)\n",
    "        return np.column_stack([p1[0] + t * (p2[0] - p1[0]), p1[1] + t * (p2[1] - p1[1])])\n",
    "\n",
    "    points = []\n",
    "\n",
    "    xmin1 = f1[x].min()\n",
    "    xmin2 = f2[x].min()\n",
    "    if xmin1 < xmin2:\n",
    "        xmin_line = sample_line(*get_endpoints('xmin'))\n",
    "        xmin_df = pd.DataFrame(xmin_line, columns=[x, z])\n",
    "        xmin_df['boundary'] = 'xmin'\n",
    "        points.append(xmin_df)\n",
    "\n",
    "    zmax_p1, zmax_p2 = get_endpoints('zmax')\n",
    "    if zmax_p1[0] < zmax_p2[0]:  # compare x-coordinates\n",
    "        zmax_line = sample_line(zmax_p1, zmax_p2)\n",
    "        zmax_df = pd.DataFrame(zmax_line, columns=[x, z])\n",
    "        zmax_df['boundary'] = 'zmax'\n",
    "        points.append(zmax_df)\n",
    "\n",
    "    if not points:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    result = pd.concat(points, ignore_index=True)\n",
    "    result['transect_idx'] = transect_idx\n",
    "    result['boundary_survey_date_1'] = d1\n",
    "    result['boundary_survey_date_2'] = d2\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filtered_transect_with_connectors(df, sampled_pts, x, z, transect_idx, date1, date2):\n",
    "    \"\"\"\n",
    "    plot box median-filtered x/z for two survey dates and the sampled bounding connector points\n",
    "    \"\"\"\n",
    "    d1, d2 = pd.to_datetime([date1, date2])\n",
    "    subset = df[(df['transect_idx'] == transect_idx) & \n",
    "                (df['survey_date'].isin([d1, d2]))]\n",
    "\n",
    "    fig, ax = plt.subplots(dpi=200)\n",
    "\n",
    "    for label, g in sampled_pts.groupby('boundary'):\n",
    "        ax.plot(g[x], g[z], marker='.', linestyle='none', markersize=1, label=f'boundary {label}')\n",
    "\n",
    "    for d in [d1, d2]:\n",
    "        sdf = subset[subset['survey_date'] == d].dropna(subset=[x, z])\n",
    "        ax.plot(sdf[x], sdf[z], label=f'{d.date()}', **STYLE_ORIG)\n",
    "\n",
    "    ax.set(xlabel='x (m)', ylabel='z (m)', title=f'transect {transect_idx} piecewise sampled + boundaries')\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1.02, 1), borderaxespad=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transects_sampled_clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_spacing = dz_piecewise * 2\n",
    "transect = 102\n",
    "date1 = '2022-04-15'\n",
    "date2 = '2025-04-04'\n",
    "\n",
    "bounding_points = create_bounding_points(all_transects_sampled_clipped, x='x_piecewise', z='z_piecewise', transect_idx=transect, date1=date1, date2=date2, spacing=boundary_spacing)\n",
    "\n",
    "plot_filtered_transect_with_connectors(all_transects_sampled_clipped, bounding_points, x='x_piecewise', z='z_piecewise', transect_idx=transect, date1=date1, date2=date2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boundary_spacing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "#### decide on which dates to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(all_transects_sampled_clipped['survey_date'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only consecutive pairs of dates\n",
    "\n",
    "all_dates = pd.to_datetime(all_transects_sampled_clipped['survey_date'].unique())\n",
    "all_dates = np.sort(all_dates)\n",
    "\n",
    "date_pairs_consec = {}\n",
    "for transect_idx, group in all_transects_sampled_clipped.groupby('transect_idx'):\n",
    "    transect_dates = sorted(group['survey_date'].unique())\n",
    "    date_pairs_consec[transect_idx] = list(zip(transect_dates[:-1], transect_dates[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "#### calculate for all transects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bounding_points_all_transects(df, x, z, transect_ids, spacing=0.1):\n",
    "    all_bounds = []\n",
    "\n",
    "    for t_id in transect_ids:\n",
    "        transect_data = df[df['transect_idx'] == t_id]\n",
    "        transect_dates = sorted(transect_data['survey_date'].unique())\n",
    "        \n",
    "        for i in range(len(transect_dates) - 1):\n",
    "            date1, date2 = transect_dates[i], transect_dates[i + 1]\n",
    "            \n",
    "            f1 = transect_data[transect_data['survey_date'] == date1]\n",
    "            f2 = transect_data[transect_data['survey_date'] == date2]\n",
    "            \n",
    "            if f1.empty or f2.empty:\n",
    "                continue\n",
    "\n",
    "            bounds = create_bounding_points(df, x, z, t_id, date1, date2, spacing=spacing)\n",
    "            if not bounds.empty:\n",
    "                all_bounds.append(bounds)\n",
    "\n",
    "    return pd.concat(all_bounds, ignore_index=True) if all_bounds else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "transects_to_use = all_transects_sampled_clipped['transect_idx'].unique()\n",
    "\n",
    "all_bounding_points = generate_bounding_points_all_transects(\n",
    "    all_transects_sampled_clipped,\n",
    "    'x_piecewise',\n",
    "    'z_piecewise',\n",
    "    transect_ids=transects_to_use,\n",
    "    spacing=boundary_spacing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_piecewise_samples_with_bounding_points(df_piecewise, df_bounding_points, x, z, transect_idx, date1, date2):\n",
    "    d1, d2 = pd.to_datetime([date1, date2])\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    for d in [d1, d2]:\n",
    "        subset = df_piecewise[\n",
    "            (df_piecewise['transect_idx'] == transect_idx) &\n",
    "            (df_piecewise['survey_date'] == d)\n",
    "        ]\n",
    "        if not subset.empty:\n",
    "            ax.plot(subset[x], subset[z], '.', label=f'{d.date()}', markersize=1)\n",
    "\n",
    "    # plot boundary points (lines will auto-connect because of ordering)\n",
    "    boundary = df_bounding_points[\n",
    "        (df_bounding_points['transect_idx'] == transect_idx) &\n",
    "        (df_bounding_points['boundary_survey_date_1'] == d1) &\n",
    "        (df_bounding_points['boundary_survey_date_2'] == d2)\n",
    "    ]\n",
    "\n",
    "    if not boundary.empty:\n",
    "        for label, g in boundary.groupby('boundary'):\n",
    "            ax.plot(g[x], g[z], marker='.', label=f'boundary {label}', markersize=1, ls='none')\n",
    "\n",
    "    ax.set(xlabel='x (m)', ylabel='z (m)',\n",
    "           title=f'transect {transect_idx} {d1.date()} to {d2.date()}')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_piecewise_samples_with_bounding_points(\n",
    "    all_transects_sampled_clipped,\n",
    "    all_bounding_points,\n",
    "    'x_piecewise',\n",
    "    'z_piecewise',\n",
    "    transect_idx=114,\n",
    "    date1='2025-04-04',\n",
    "    date2='2025-08-22'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "### aggregate boundary points and create internal points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_perimeter_points_per_transect(df_piecewise, df_bounding_points, x, z, transect_idx, date1, date2):\n",
    "    d1, d2 = pd.to_datetime([date1, date2])\n",
    "\n",
    "    transect1 = df_piecewise[(df_piecewise['transect_idx'] == transect_idx) & (df_piecewise['survey_date'] == d1)].copy()\n",
    "    transect2 = df_piecewise[(df_piecewise['transect_idx'] == transect_idx) & (df_piecewise['survey_date'] == d2)].copy()\n",
    "\n",
    "    boundary = df_bounding_points[\n",
    "        (df_bounding_points['transect_idx'] == transect_idx) &\n",
    "        (df_bounding_points['boundary_survey_date_1'] == d1) &\n",
    "        (df_bounding_points['boundary_survey_date_2'] == d2)\n",
    "    ]\n",
    "\n",
    "    keep_cols = [x, z, 'transect_idx', 'survey_date', 'boundary_survey_date_1', 'boundary_survey_date_2', 'boundary']\n",
    "\n",
    "    perimeter = pd.concat([transect1, transect2, boundary], ignore_index=True)[keep_cols]\n",
    "    perimeter['point_type'] = 'perimeter'\n",
    "    \n",
    "    return perimeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_and_add_random_points_to_transect(df_perimeter, x, z, slice_width=0.1, density_scale=100):\n",
    "    \"\"\"\n",
    "    fill vertical slices in z with random points in (x, z) where x between xmin and xmax\n",
    "    \"\"\"\n",
    "    zmin, zmax = df_perimeter[z].min(), df_perimeter[z].max()\n",
    "    slices = np.arange(zmin, zmax, slice_width)\n",
    "    all_random_points = []\n",
    "\n",
    "    sorted_dates = np.sort(df_perimeter['survey_date'].dropna().unique())\n",
    "    if len(sorted_dates) > 2:\n",
    "        print('more than two survey dates in df!')\n",
    "    earlier_survey, later_survey = sorted_dates[0], sorted_dates[1]\n",
    "\n",
    "    for z0 in slices:\n",
    "        z1 = z0 + slice_width\n",
    "        slice = df_perimeter[(df_perimeter[z] >= z0) & (df_perimeter[z] < z1)]\n",
    "\n",
    "        if slice.empty or slice[z].nunique() < 2:\n",
    "            continue\n",
    "\n",
    "        slice_earlier = slice[slice['survey_date'] == earlier_survey]\n",
    "        slice_later = slice[slice['survey_date'] == later_survey]\n",
    "\n",
    "        x_min, x_max = slice[x].min(), slice[x].max()\n",
    "        x_earlier = slice_earlier[x].median()\n",
    "        x_later = slice_later[x].median()\n",
    "\n",
    "        # skip if deposition (x moved left)\n",
    "        if x_later <= x_earlier or x_min == x_max:\n",
    "            continue\n",
    "\n",
    "        # assign boundary label only if slice bounds are defined by boundary-tagged points\n",
    "        boundary_label = None\n",
    "        boundary_points = slice[slice['boundary'].notna()]\n",
    "\n",
    "        if not boundary_points.empty:\n",
    "            bx_min, bx_max = boundary_points[x].min(), boundary_points[x].max()\n",
    "\n",
    "            # check if bounds match those of the full slice\n",
    "            x_bounds_match = np.isclose(x_min, bx_min) and np.isclose(x_max, bx_max)\n",
    "\n",
    "            # check if those same bounds are also matched by points in slice_earlier or slice_later\n",
    "            ex_min = pd.concat([slice_earlier, slice_later])[x].min()\n",
    "            ex_max = pd.concat([slice_earlier, slice_later])[x].max()\n",
    "            bounds_overlap_with_surveys = np.isclose(x_min, ex_min) or np.isclose(x_max, ex_max)\n",
    "\n",
    "            if x_bounds_match and not bounds_overlap_with_surveys:\n",
    "                boundary_label = boundary_points['boundary'].iloc[0]\n",
    "\n",
    "        # generate random points within slice\n",
    "        slice_area = (x_max - x_min) * (z1 - z0)\n",
    "        n_points = max(1, int(slice_area * density_scale))  # linear scaling\n",
    "        z_rand = np.random.uniform(z0, z1, n_points)\n",
    "        x_rand = np.random.uniform(x_min, x_max, n_points)\n",
    "        pts = pd.DataFrame({x: x_rand, z: z_rand,\n",
    "                            'z_slice_min': np.round(z0, 2), 'z_slice_max': np.round(z1, 2)})\n",
    "\n",
    "        if boundary_label:\n",
    "            pts['boundary'] = boundary_label\n",
    "        if 'transect_idx' in df_perimeter.columns:\n",
    "            pts['transect_idx'] = df_perimeter['transect_idx'].iloc[0]\n",
    "\n",
    "        all_random_points.append(pts)\n",
    "        \n",
    "    if all_random_points:\n",
    "        random_df = pd.concat(all_random_points, ignore_index=True)\n",
    "        random_df['random_survey_date_1'] = earlier_survey\n",
    "        random_df['random_survey_date_2'] = later_survey\n",
    "        random_df['point_type'] = 'random'\n",
    "    else:\n",
    "        random_df = pd.DataFrame()\n",
    "\n",
    "    return random_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filled_with_bounds(df_perimeter, df_random):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    transect_idx = df_perimeter['transect_idx'].iloc[0]\n",
    "    dates = df_perimeter['survey_date'].unique().dropna()\n",
    "    d1, d2 = dates[0], dates[1]\n",
    "\n",
    "    ax.plot(df_perimeter['x_piecewise'], df_perimeter['z_piecewise'], '.', color='gray', alpha=0.6, label='boundary points')\n",
    "    ax.plot(df_random['x_piecewise'], df_random['z_piecewise'], '.', color='orange', markersize=2, label='filled points')\n",
    "\n",
    "    ax.set(title=f'transect {transect_idx}: filled area between {d1.date()} and {d2.date()}',\n",
    "           xlabel='x (m)', ylabel='z (m)')\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_perimeter_point_slices_with_deposition(df_perimeter, x, z, slice_width=0.1):\n",
    "    zmin, zmax = df_perimeter[z].min(), df_perimeter[z].max()\n",
    "    slices = np.arange(zmin, zmax, slice_width)\n",
    "    slices_to_keep = []\n",
    "\n",
    "    sorted_dates = np.sort(df_perimeter['survey_date'].dropna().unique())\n",
    "\n",
    "    for z0 in slices:\n",
    "        z1 = z0 + slice_width\n",
    "        slice_df = df_perimeter[(df_perimeter[z] >= z0) & (df_perimeter[z] < z1)]\n",
    "\n",
    "        slice_earlier = slice_df[slice_df['survey_date'] == sorted_dates[0]]\n",
    "        slice_later = slice_df[slice_df['survey_date'] == sorted_dates[1]]\n",
    "\n",
    "        x_earlier = slice_earlier[x].median()\n",
    "        x_later = slice_later[x].median()\n",
    "\n",
    "        if x_later <= x_earlier:\n",
    "            continue\n",
    "\n",
    "        slices_to_keep.append(slice_df)\n",
    "\n",
    "    only_erosion = pd.concat(slices_to_keep, ignore_index=True) if slices_to_keep else pd.DataFrame()\n",
    "\n",
    "    return only_erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "transects_to_use = all_transects_sampled_clipped['transect_idx'].unique()\n",
    "x = 'x_piecewise'\n",
    "z = 'z_piecewise'\n",
    "slice_width = 0.1  # meters\n",
    "\n",
    "list_of_perimeter_plus_random = []\n",
    "\n",
    "for transect_count, transect_idx in enumerate(transects_to_use, start=1):\n",
    "    print(f'▶️ processing transect {transect_count}/{len(transects_to_use)} (transect_idx={transect_idx})')\n",
    "    \n",
    "    transect_data = all_transects_sampled_clipped[all_transects_sampled_clipped['transect_idx'] == transect_idx]\n",
    "    transect_dates = sorted(transect_data['survey_date'].unique())\n",
    "    \n",
    "    for i in range(len(transect_dates) - 1):\n",
    "        date1, date2 = transect_dates[i], transect_dates[i + 1]\n",
    "        print(f'  ⏳ {date1.date()} → {date2.date()}')\n",
    "\n",
    "        perimeter_points = aggregate_perimeter_points_per_transect(\n",
    "            all_transects_sampled_clipped,\n",
    "            all_bounding_points,\n",
    "            x, z,\n",
    "            transect_idx,\n",
    "            date1, date2\n",
    "        )\n",
    "\n",
    "        cleaned_perimeter = remove_perimeter_point_slices_with_deposition(perimeter_points, x, z, slice_width)\n",
    "        random_points = slice_and_add_random_points_to_transect(perimeter_points, x, z, slice_width, 150)\n",
    "\n",
    "        perimeter_plus_random = pd.concat([cleaned_perimeter, random_points], ignore_index=True)\n",
    "        list_of_perimeter_plus_random.append(perimeter_plus_random)\n",
    "\n",
    "all_cleaned_perimeter_plus_random = pd.concat(list_of_perimeter_plus_random, ignore_index=True) if list_of_perimeter_plus_random else pd.DataFrame()\n",
    "all_cleaned_perimeter_plus_random.to_parquet('data/perimeter_plus_random_points.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cleaned_perimeter_plus_random = pd.read_parquet('data/perimeter_plus_random_points.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bounding_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_transect = 113\n",
    "date1 = '2024-09-06'\n",
    "date2 = '2025-04-04'\n",
    "x = 'x_piecewise'\n",
    "z = 'z_piecewise'\n",
    "slice_width = 0.1\n",
    "\n",
    "perimeter_points = aggregate_perimeter_points_per_transect(\n",
    "    all_transects_sampled_clipped,\n",
    "    all_bounding_points, x=x, z=z, transect_idx=plot_transect, date1=date1, date2=date2)\n",
    "\n",
    "random_points = slice_and_add_random_points_to_transect(perimeter_points, x, z, slice_width, 150)\n",
    "cleaned_perimeter = remove_perimeter_point_slices_with_deposition(perimeter_points, x, z, slice_width)\n",
    "perimeter_plus_random = pd.concat([perimeter_points, random_points], ignore_index=True)\n",
    "plot_filled_with_bounds(cleaned_perimeter, random_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = all_cleaned_perimeter_plus_random[\n",
    "    (all_cleaned_perimeter_plus_random['transect_idx'] == plot_transect) &\n",
    "    (all_cleaned_perimeter_plus_random['survey_date'].isin([pd.to_datetime(date1), pd.to_datetime(date2)]))\n",
    "]\n",
    "fig, ax = plt.subplots()\n",
    "scatter = ax.scatter(filter[x], filter[z], c=filter['survey_date'], s=1, alpha=0.5)\n",
    "\n",
    "unique_dates = sorted(filter['survey_date'].unique())\n",
    "date_labels = [pd.to_datetime(date).strftime('%Y-%m-%d') for date in unique_dates]\n",
    "\n",
    "handles, _ = scatter.legend_elements()\n",
    "ax.legend(handles, date_labels, title=\"survey date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cleaned_perimeter_plus_random.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "### alpha shape :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset(df, transect_idx, date1, date2, date_col1, date_col2=None):\n",
    "    if date_col2:\n",
    "        return df[(df['transect_idx'] == transect_idx) & (df[date_col1] == date1) & (df[date_col2] == date2)]\n",
    "    else:\n",
    "        return df[(df['transect_idx'] == transect_idx) & ((df[date_col1] == date1) | (df[date_col1] == date2))]\n",
    "\n",
    "def deduplicate(df, x_col, z_col, tolerance=0.02):\n",
    "    df['x_rounded'] = (df[x_col] / tolerance).round().astype(int)\n",
    "    df['z_rounded'] = (df[z_col] / tolerance).round().astype(int)\n",
    "    df = df.drop_duplicates(subset=['x_rounded', 'z_rounded'])\n",
    "    df = df.drop(columns=['x_rounded', 'z_rounded'])\n",
    "    return list(zip(df[x_col], df[z_col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old version no error handling\n",
    "\n",
    "# alpha_val = 2.5\n",
    "# alpha_shapes = []\n",
    "# records = []\n",
    "# df_points = all_cleaned_perimeter_plus_random\n",
    "\n",
    "# for transect_idx, transect_data in df_points.groupby('transect_idx'):\n",
    "#     all_dates = transect_data['survey_date'].dropna().unique()\n",
    "#     transect_dates = sorted(all_dates)\n",
    "\n",
    "#     for i in range(len(transect_dates) - 1):\n",
    "#         date1, date2 = transect_dates[i], transect_dates[i + 1]\n",
    "#         print(f' {transect_idx} ⏳ {pd.Timestamp(date1).date()} → {pd.Timestamp(date2).date()}', end='\\r')\n",
    "\n",
    "#         transects = get_subset(df_points, transect_idx, date1, date2, 'survey_date')\n",
    "#         boundaries = get_subset(df_points, transect_idx, date1, date2, 'boundary_survey_date_1', 'boundary_survey_date_2')\n",
    "#         random = get_subset(df_points, transect_idx, date1, date2, 'random_survey_date_1', 'random_survey_date_2')\n",
    "\n",
    "#         aggregated = pd.concat([transects, boundaries, random], ignore_index=True)\n",
    "#         points_2d = deduplicate(aggregated, 'x_piecewise', 'z_piecewise')\n",
    "\n",
    "#         poly = alphashape.alphashape(points_2d, alpha_val)\n",
    "\n",
    "#         area = poly.area\n",
    "#         polygon_index = len(alpha_shapes)\n",
    "\n",
    "#         alpha_shapes.append(poly)\n",
    "#         records.append({\n",
    "#             'transect_idx': transect_idx,\n",
    "#             'alphashape_survey_date_1': date1,\n",
    "#             'alphashape_survey_date_2': date2,\n",
    "#             'alpha': alpha_val,\n",
    "#             'area': area,\n",
    "#             'polygon_index': polygon_index\n",
    "#         })\n",
    "\n",
    "# alpha_metadata = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW CODE 7:52 PM\n",
    "\n",
    "def compute_alphashape_with_fallback(points_2d, initial_alpha=3.0, min_alpha=1.0, min_coverage=0.7):\n",
    "    \"\"\"\n",
    "    compute alphashape with decreasing alpha values as fallback\n",
    "    returns (polygon, final_alpha, coverage_fraction, error_info)\n",
    "    \"\"\"\n",
    "    if not isinstance(points_2d, np.ndarray):\n",
    "        points_2d = np.array(points_2d)\n",
    "    alpha = initial_alpha\n",
    "    error_log = []\n",
    "    \n",
    "    # buffer distance for \"close to\" polygon (1% of bounding box diagonal)\n",
    "    x_range = points_2d[:, 0].max() - points_2d[:, 0].min()\n",
    "    z_range = points_2d[:, 1].max() - points_2d[:, 1].min()\n",
    "    buffer_dist = 0.01 * np.sqrt(x_range**2 + z_range**2)\n",
    "    \n",
    "    while alpha >= min_alpha:\n",
    "        try:\n",
    "            poly = alphashape.alphashape(points_2d, alpha)\n",
    "            \n",
    "            # check if result is valid (not empty)\n",
    "            if poly is None or poly.is_empty:\n",
    "                error_log.append(f\"alpha {alpha:.1f}: empty result\")\n",
    "                alpha -= 0.5\n",
    "                continue\n",
    "            \n",
    "            # check point coverage\n",
    "            buffered_poly = poly.buffer(buffer_dist)\n",
    "            points_geom = [Point(x, z) for x, z in points_2d]\n",
    "            covered_points = sum(buffered_poly.contains(pt) for pt in points_geom)\n",
    "            coverage_fraction = covered_points / len(points_2d)\n",
    "            \n",
    "            # accept if coverage is sufficient\n",
    "            if coverage_fraction >= min_coverage:\n",
    "                return poly, alpha, coverage_fraction, None\n",
    "            else:\n",
    "                error_log.append(f\"alpha {alpha:.1f}: low coverage ({coverage_fraction:.2f})\")\n",
    "                alpha -= 0.5\n",
    "                continue\n",
    "                \n",
    "        except Exception as e:\n",
    "            error_info = f\"alpha {alpha:.1f}: {type(e).__name__}: {str(e)}\"\n",
    "            error_log.append(error_info)\n",
    "            alpha -= 0.5\n",
    "    \n",
    "    # if all alpha values failed\n",
    "    full_error = \"; \".join(error_log)\n",
    "    return None, None, None, full_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {},
   "source": [
    "use this for computation but parquet is updated and it is slow to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_val = 3.0\n",
    "alpha_shapes = []\n",
    "records = []\n",
    "df_points = all_cleaned_perimeter_plus_random\n",
    "\n",
    "for transect_idx, transect_data in df_points.groupby('transect_idx'):\n",
    "    all_dates = transect_data['survey_date'].dropna().unique()\n",
    "    transect_dates = sorted(all_dates)\n",
    "\n",
    "    for i in range(len(transect_dates) - 1):\n",
    "        date1, date2 = transect_dates[i], transect_dates[i + 1]\n",
    "        print(f' {transect_idx} ⏳ {pd.Timestamp(date1).date()} → {pd.Timestamp(date2).date()}', end='\\r')\n",
    "\n",
    "        transects = get_subset(df_points, transect_idx, date1, date2, 'survey_date')\n",
    "        boundaries = get_subset(df_points, transect_idx, date1, date2, 'boundary_survey_date_1', 'boundary_survey_date_2')\n",
    "        random = get_subset(df_points, transect_idx, date1, date2, 'random_survey_date_1', 'random_survey_date_2')\n",
    "\n",
    "        aggregated = pd.concat([transects, boundaries, random], ignore_index=True)\n",
    "        points_2d = deduplicate(aggregated, 'x_piecewise', 'z_piecewise')\n",
    "        \n",
    "        # diagnostic info\n",
    "        n_points = len(points_2d)\n",
    "        \n",
    "        poly, final_alpha, coverage_fraction, error_info = compute_alphashape_with_fallback(points_2d, alpha_val)\n",
    "        \n",
    "        if poly is not None:\n",
    "            area = poly.area\n",
    "            polygon_index = len(alpha_shapes)\n",
    "            alpha_shapes.append(poly)\n",
    "            \n",
    "            records.append({\n",
    "                'transect_idx': transect_idx,\n",
    "                'alphashape_survey_date_1': date1,\n",
    "                'alphashape_survey_date_2': date2,\n",
    "                'alpha': final_alpha,\n",
    "                'area': area,\n",
    "                'polygon_index': polygon_index,\n",
    "                'n_points': n_points,\n",
    "                'coverage_fraction': coverage_fraction,\n",
    "                'alpha_changed': final_alpha != alpha_val,\n",
    "                'error_info': None\n",
    "            })\n",
    "        else:\n",
    "            # failed to compute alphashape\n",
    "            print(f\"\\nFAILED: transect {transect_idx}, {pd.Timestamp(date1).date()} → {pd.Timestamp(date2).date()}\")\n",
    "            print(f\"  points: {n_points}, errors: {error_info}\")\n",
    "            \n",
    "            records.append({\n",
    "                'transect_idx': transect_idx,\n",
    "                'alphashape_survey_date_1': date1,\n",
    "                'alphashape_survey_date_2': date2,\n",
    "                'alpha': None,\n",
    "                'area': None,\n",
    "                'polygon_index': None,\n",
    "                'n_points': n_points,\n",
    "                'coverage_fraction': None,\n",
    "                'alpha_changed': None,\n",
    "                'error_info': error_info\n",
    "            })\n",
    "\n",
    "alpha_metadata = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_metadata.to_parquet('data/alpha_metadata.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_metadata = pd.read_parquet('data/alpha_metadata.parquet')\n",
    "alpha_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_metadata[alpha_metadata['error_info'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_metadata = alpha_metadata.dropna(subset='polygon_index')\n",
    "remaining_indices = alpha_metadata['polygon_index'].astype(int).tolist().copy()\n",
    "\n",
    "alpha_shapes = [alpha_shapes[i] for i in remaining_indices]\n",
    "alpha_metadata['polygon_index'] = range(len(alpha_metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_metadata[alpha_metadata['alpha_changed'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_alpha_shape_with_points(transect_idx, date1, date2, alpha_metadata, alpha_shapes, all_points):\n",
    "    date1, date2 = pd.to_datetime(date1), pd.to_datetime(date2)\n",
    "\n",
    "    match = get_subset(alpha_metadata, transect_idx, date1, date2, 'alphashape_survey_date_1', 'alphashape_survey_date_2')\n",
    "\n",
    "    row = match.iloc[0]\n",
    "    poly, area, alpha = alpha_shapes[row['polygon_index']], row['area'], row['alpha']\n",
    "\n",
    "    transects = get_subset(all_points, transect_idx, date1, date2, 'survey_date')\n",
    "    boundaries = get_subset(all_points, transect_idx, date1, date2, 'boundary_survey_date_1', 'boundary_survey_date_2')\n",
    "    random = get_subset(all_points, transect_idx, date1, date2, 'random_survey_date_1', 'random_survey_date_2')\n",
    "\n",
    "    aggregated = pd.concat([transects, boundaries, random], ignore_index=True)\n",
    "\n",
    "    fig, ax = plt.subplots(dpi=150)\n",
    "\n",
    "    if isinstance(poly, Polygon):\n",
    "        x, y = poly.exterior.xy\n",
    "        ax.fill(x, y, alpha=0.3, facecolor='gray', edgecolor='black', label='')\n",
    "    elif isinstance(poly, MultiPolygon):\n",
    "        for p in poly.geoms:\n",
    "            x, y = p.exterior.xy\n",
    "            ax.fill(x, y, alpha=0.3, facecolor='gray', edgecolor='black', label='')\n",
    "\n",
    "    ax.plot(transects['x_piecewise'], transects['z_piecewise'], '.', markersize=1, label='transects', alpha=1)\n",
    "    ax.plot(boundaries['x_piecewise'], boundaries['z_piecewise'], '.', markersize=1, label='boundaries', alpha=1)\n",
    "    ax.plot(random['x_piecewise'], random['z_piecewise'], '.', markersize=1, label='random', alpha=1)\n",
    "\n",
    "    ax.set_title(f'transect {transect_idx}, {date1.date()} → {date2.date()}\\nalpha = {alpha}, area = {area:.2f} m²')\n",
    "    ax.set_xlabel('x (m)')\n",
    "    ax.set_ylabel('z (m)')\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.set_aspect('equal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_alpha_shape_with_points(\n",
    "    transect_idx=61,\n",
    "    date1='2022-09-21',\n",
    "    date2='2023-01-07',\n",
    "    alpha_metadata=alpha_metadata,\n",
    "    alpha_shapes=alpha_shapes,\n",
    "    all_points=all_cleaned_perimeter_plus_random\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_metadata['alphashape_survey_date_1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dates = sorted(alpha_metadata['alphashape_survey_date_1'].unique())\n",
    "unique_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_alpha_shape_with_points_3transects_all_dates(transect_idxs, alpha_metadata, alpha_shapes, all_points):\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20 * centimeters, 5 * centimeters), gridspec_kw={'wspace': 0.02}, dpi=600)\n",
    "    \n",
    "    unique_dates = sorted(alpha_metadata['alphashape_survey_date_1'].unique())\n",
    "    colors = plt.cm.twilight_shifted(np.linspace(0, 0.9, 11))\n",
    "    date_color_map = dict(zip(unique_dates, colors))\n",
    "    \n",
    "    all_x_vals = []\n",
    "    all_z_vals = []\n",
    "    \n",
    "    for transect_idx in transect_idxs:\n",
    "        transect_metadata = alpha_metadata[alpha_metadata['transect_idx'] == transect_idx]\n",
    "        \n",
    "        for _, row in transect_metadata.iterrows():\n",
    "            date1, date2 = row['alphashape_survey_date_1'], row['alphashape_survey_date_2']\n",
    "            \n",
    "            transects = get_subset(all_points, transect_idx, date1, date2, 'survey_date')\n",
    "            boundaries = get_subset(all_points, transect_idx, date1, date2, 'boundary_survey_date_1', 'boundary_survey_date_2')\n",
    "            random = get_subset(all_points, transect_idx, date1, date2, 'random_survey_date_1', 'random_survey_date_2')\n",
    "            \n",
    "            aggregated = pd.concat([transects, boundaries, random], ignore_index=True)\n",
    "            if not aggregated.empty:\n",
    "                all_x_vals.extend(aggregated['x_piecewise'])\n",
    "                all_z_vals.extend(aggregated['z_piecewise'])\n",
    "    \n",
    "    x_padding = (max(all_x_vals) - min(all_x_vals)) * 0.05\n",
    "    z_padding = (max(all_z_vals) - min(all_z_vals)) * 0.05\n",
    "    xlim = (min(all_x_vals) - x_padding, max(all_x_vals) + x_padding)\n",
    "    zlim = (min(all_z_vals) - z_padding, max(all_z_vals) + z_padding)\n",
    "    \n",
    "    for plot_idx, transect_idx in enumerate(transect_idxs):\n",
    "        ax = axes[plot_idx]\n",
    "        \n",
    "        transect_metadata = alpha_metadata[alpha_metadata['transect_idx'] == transect_idx]\n",
    "        \n",
    "        for _, row in transect_metadata.iterrows():\n",
    "            date1, date2 = row['alphashape_survey_date_1'], row['alphashape_survey_date_2']\n",
    "            poly = alpha_shapes[row['polygon_index']]\n",
    "            survey_date_1 = row['alphashape_survey_date_1']\n",
    "            \n",
    "            color = date_color_map[survey_date_1]\n",
    "            \n",
    "            if isinstance(poly, Polygon):\n",
    "                x, y = poly.exterior.xy\n",
    "                ax.fill(x, y, alpha=0.3, facecolor=color, edgecolor=color, linewidth=1)\n",
    "            elif isinstance(poly, MultiPolygon):\n",
    "                for p in poly.geoms:\n",
    "                    x, y = p.exterior.xy\n",
    "                    ax.fill(x, y, alpha=0.3, facecolor=color, edgecolor=color, linewidth=1)\n",
    "            \n",
    "            transects = get_subset(all_points, transect_idx, date1, date2, 'survey_date')\n",
    "            boundaries = get_subset(all_points, transect_idx, date1, date2, 'boundary_survey_date_1', 'boundary_survey_date_2')\n",
    "            random = get_subset(all_points, transect_idx, date1, date2, 'random_survey_date_1', 'random_survey_date_2')\n",
    "\n",
    "            # color *= 0.7\n",
    "            \n",
    "            ax.plot(transects['x_piecewise'], transects['z_piecewise'], '.', \n",
    "                markersize=1, alpha=1, color=color, rasterized=True, mew=0, zorder=10)\n",
    "        \n",
    "            ax.plot(boundaries['x_piecewise'], boundaries['z_piecewise'], '.', \n",
    "                markersize=1, alpha=0.7, color=color, rasterized=True, mew=0)\n",
    "        \n",
    "            ax.plot(random['x_piecewise'], random['z_piecewise'], '.', \n",
    "                markersize=1, alpha=0.7, color=color, rasterized=True, mew=0)\n",
    "        \n",
    "        ax.set_xlabel('distance along transect (m)' if plot_idx == 1 else '')  # Only middle subplot\n",
    "        ax.set_ylabel('z (m)' if plot_idx == 0 else '')  # Only first subplot\n",
    "        # ax.set_title(f'transect {transect_idx}')\n",
    "        ax.set_xlim(xlim)\n",
    "        ax.set_ylim(zlim)\n",
    "        ax.tick_params(axis='both', pad=3)\n",
    "        ax.set_xlim(-0.48, 13.7)\n",
    "        ax.set_ylim(3.36, 11.55)\n",
    "        \n",
    "        if plot_idx > 0:\n",
    "            ax.set_yticks([])\n",
    "    \n",
    "    # axes[0].legend(loc='upper left', markerscale=3, handletextpad=0.2)\n",
    "    plt.tight_layout()\n",
    "    os.makedirs('f2-alphashapes', exist_ok=True)\n",
    "    transect_str = '_'.join(map(str, transect_idxs))\n",
    "    fig.savefig(f'f2-alphashapes/alphashapes_all_dates_{transect_str}.pdf', \n",
    "               bbox_inches='tight', pad_inches=0.05, dpi=600)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_alpha_shape_with_points_3transects_all_dates(\n",
    "    [21, 60, 96], \n",
    "    alpha_metadata, \n",
    "    alpha_shapes, \n",
    "    all_cleaned_perimeter_plus_random\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_piecewise_sampled_vs_box_filtered_profile_3transects(df_box_filtered, df_piecewise_sampled, transect_idxs, dates):\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20 * centimeters, 5 * centimeters), gridspec_kw={'wspace': 0.02})\n",
    "    dates = pd.to_datetime(dates)\n",
    "    colors = plt.cm.twilight_shifted(np.linspace(0, 0.9, len(dates)))\n",
    "    \n",
    "    all_x_vals = []\n",
    "    all_z_vals = []\n",
    "    \n",
    "    for transect_idx in transect_idxs:\n",
    "        for date in dates:\n",
    "            f = df_box_filtered[\n",
    "                (df_box_filtered['transect_idx'] == transect_idx) &\n",
    "                (df_box_filtered['survey_date'] == date)\n",
    "            ].dropna(subset=['x_box_median', 'z_box_median'])\n",
    "            \n",
    "            s = df_piecewise_sampled[\n",
    "                (df_piecewise_sampled['transect_idx'] == transect_idx) & \n",
    "                (df_piecewise_sampled['survey_date'] == date)\n",
    "            ]\n",
    "            \n",
    "            if not f.empty:\n",
    "                all_x_vals.extend(f['x_box_median'])\n",
    "                all_z_vals.extend(f['z_box_median'])\n",
    "            if not s.empty:\n",
    "                all_x_vals.extend(s['x_piecewise'])\n",
    "                all_z_vals.extend(s['z_piecewise'])\n",
    "    \n",
    "    x_padding = (max(all_x_vals) - min(all_x_vals)) * 0.05\n",
    "    z_padding = (max(all_z_vals) - min(all_z_vals)) * 0.05\n",
    "    xlim = (min(all_x_vals) - x_padding, max(all_x_vals) + x_padding)\n",
    "    zlim = (min(all_z_vals) - z_padding, max(all_z_vals) + z_padding)\n",
    "    \n",
    "    for plot_idx, transect_idx in enumerate(transect_idxs):\n",
    "        ax = axes[plot_idx]\n",
    "        \n",
    "        for i, date in enumerate(dates):    \n",
    "            f = df_box_filtered[\n",
    "                (df_box_filtered['transect_idx'] == transect_idx) &\n",
    "                (df_box_filtered['survey_date'] == date)\n",
    "            ].dropna(subset=['x_box_median', 'z_box_median'])\n",
    "\n",
    "            s = df_piecewise_sampled[\n",
    "                (df_piecewise_sampled['transect_idx'] == transect_idx) & \n",
    "                (df_piecewise_sampled['survey_date'] == date)\n",
    "            ]\n",
    "            \n",
    "            base_color = np.minimum(colors[i] + 0.1, 1.0)\n",
    "            dark_color = base_color * 0.7\n",
    "\n",
    "            if not f.empty:\n",
    "                ax.plot(f['x_box_median'], f['z_box_median'], '.', alpha=0.1, markersize=6, color=base_color, mew=0, rasterized=True)\n",
    "            if not s.empty:\n",
    "                label = date.strftime('%Y-%m-%d') if plot_idx == 0 else None  # Only label first subplot\n",
    "                ax.plot(s['x_piecewise'], s['z_piecewise'], '.', markersize=2, label=label, color=dark_color, mew=0, alpha=1, rasterized=True)\n",
    "\n",
    "        # ax.set_xlabel('x (m)')\n",
    "        ax.set_ylabel('z (m)' if plot_idx == 0 else '')  # Only label y-axis for first subplot\n",
    "        ax.set_title(f'transect {transect_idx}')\n",
    "        ax.set_xlim(xlim)\n",
    "        ax.set_ylim(zlim)\n",
    "        ax.tick_params(axis='both', pad=3)\n",
    "        ax.set_xticks([])\n",
    "        # ax.set_xticks([1, 4, 7, 9])\n",
    "        # for ax in axes:\n",
    "        #     ax.grid(axis='y', linestyle='-', alpha=0.5)\n",
    "\n",
    "        if plot_idx > 0:\n",
    "            ax.set_yticks([])\n",
    "            # ax.spines['left'].set_visible(False)\n",
    "            # ax.spines['right'].set_visible(False)\n",
    "        if plot_idx != 1:\n",
    "            ax.set_xlabel('')\n",
    "    \n",
    "    axes[0].legend(loc='upper left', bbox_to_anchor=(3.05, 1.05), markerscale=3, handletextpad=0.2)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    os.makedirs('f2-alphashapes', exist_ok=True)\n",
    "    transect_str = '_'.join(map(str, transect_idxs))\n",
    "    fig.savefig(f'f2-alphashapes/transects_{transect_str}.pdf', bbox_inches='tight', pad_inches=0.05, dpi=600)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_piecewise_sampled_vs_box_filtered_profile_3transects(\n",
    "    all_transects_filt_add_max, \n",
    "    all_transects_sampled, \n",
    "    [21, 60, 96], \n",
    "    dates\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transect_evolution(transect_idx):\n",
    "    transect_data = all_cleaned_perimeter_plus_random[all_cleaned_perimeter_plus_random['transect_idx'] == transect_idx]\n",
    "    transect_dates = sorted(transect_data['survey_date'].dropna().unique())\n",
    "    date_pairs = list(zip(transect_dates[:-1], transect_dates[1:]))\n",
    "\n",
    "    fig, ax = plt.subplots(dpi=150)\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(date_pairs)))\n",
    "    \n",
    "    plotted_pairs = []  # track successfully plotted pairs for color indexing\n",
    "\n",
    "    for i, (date1, date2) in enumerate(date_pairs):\n",
    "        date1, date2 = pd.to_datetime(date1), pd.to_datetime(date2)\n",
    "        match = get_subset(alpha_metadata, transect_idx, date1, date2, 'alphashape_survey_date_1', 'alphashape_survey_date_2')\n",
    "        \n",
    "        # check if match exists (not empty after dropping failed rows)\n",
    "        if match.empty:\n",
    "            print(f\"Skipping {transect_idx} {date1.date()} → {date2.date()}: no alphashape available\")\n",
    "            continue\n",
    "            \n",
    "        row = match.iloc[0]\n",
    "        poly, area, alpha = alpha_shapes[row['polygon_index']], row['area'], row['alpha']\n",
    "        color_idx = len(plotted_pairs)  # use number of plotted pairs for consistent coloring\n",
    "\n",
    "        if isinstance(poly, Polygon):\n",
    "            x, y = poly.exterior.xy\n",
    "            ax.fill(x, y, alpha=0.3, facecolor=colors[color_idx], edgecolor='black', \n",
    "                   label=f'{date1.date()} → {date2.date()}, {area:.2f} m²')\n",
    "        elif isinstance(poly, MultiPolygon):\n",
    "            for j, p in enumerate(poly.geoms):\n",
    "                x, y = p.exterior.xy\n",
    "                label = f'{date1.date()} → {date2.date()}, {area:.2f} m²' if j == 0 else None\n",
    "                ax.fill(x, y, alpha=0.3, facecolor=colors[color_idx], edgecolor='black', label=label)\n",
    "                \n",
    "        transects = get_subset(all_cleaned_perimeter_plus_random, transect_idx, date1, date2, 'survey_date')\n",
    "        boundaries = get_subset(all_cleaned_perimeter_plus_random, transect_idx, date1, date2, 'boundary_survey_date_1', 'boundary_survey_date_2')\n",
    "        random = get_subset(all_cleaned_perimeter_plus_random, transect_idx, date1, date2, 'random_survey_date_1', 'random_survey_date_2')\n",
    "\n",
    "        ax.plot(transects['x_piecewise'], transects['z_piecewise'], '.', markersize=1, color=colors[color_idx], alpha=0.7)\n",
    "        ax.plot(boundaries['x_piecewise'], boundaries['z_piecewise'], '.', markersize=1, color=colors[color_idx], alpha=0.7)\n",
    "        ax.plot(random['x_piecewise'], random['z_piecewise'], '.', markersize=1, color=colors[color_idx], alpha=0.7)\n",
    "        \n",
    "        plotted_pairs.append((date1, date2))\n",
    "    \n",
    "    # only create plot if we have data to plot\n",
    "    if plotted_pairs:\n",
    "        ax.set_xlabel('x (m)')\n",
    "        ax.set_ylabel('z (m)')\n",
    "        ax.legend(loc='upper left', bbox_to_anchor=(1.02, 1), borderaxespad=0)\n",
    "        ax.set_title(f'transect {transect_idx}')\n",
    "        # ax.set_aspect('equal')\n",
    "\n",
    "        os.makedirs('sandbox/check-alpha', exist_ok=True)\n",
    "        fig.savefig(f'sandbox/check-alpha/transect_{transect_idx}', dpi=400, bbox_inches='tight')\n",
    "    else:\n",
    "        print(f\"No valid alphashapes to plot for transect {transect_idx}\")\n",
    "\n",
    "    # plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for t_idx in all_cleaned_perimeter_plus_random['transect_idx'].unique():\n",
    "#    plot_transect_evolution(transect_idx=t_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_areas = np.sort(alpha_metadata['area'] / 6.5)\n",
    "cumulative_freq = np.arange(1, len(sorted_areas) + 1)\n",
    "\n",
    "# Plot\n",
    "plt.plot(sorted_areas, cumulative_freq)\n",
    "plt.xlabel('mean retreat distance (m)')\n",
    "plt.ylabel('Cumulative Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_metadata['area'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_metadata['area'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_metadata.groupby('alphashape_survey_date_1')['area'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_metadata.groupby('transect_idx')['area'].min().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_to_plot = alpha_metadata[\n",
    "    alpha_metadata['alphashape_survey_date_1'] == pd.to_datetime('2022-04-15')\n",
    "    ]\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dates = alpha_metadata['alphashape_survey_date_1'].unique()\n",
    "n_plots = len(unique_dates)\n",
    "\n",
    "# create figure with shared axes\n",
    "fig, axes = plt.subplots(n_plots, 1, figsize=(19 * centimeters, 1.5*n_plots * centimeters), \n",
    "                        sharex=True, sharey=True, gridspec_kw={'hspace':0.1})\n",
    "\n",
    "# ensure axes is always a list (handles case of single subplot)\n",
    "if n_plots == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, date in enumerate(unique_dates):\n",
    "    date_data = alpha_metadata[alpha_metadata['alphashape_survey_date_1'] == date]\n",
    "    date2 = date_data['alphashape_survey_date_2'].iloc[0]\n",
    "    \n",
    "    # plot data on current axis\n",
    "    axes[i].scatter(date_data['transect_idx'], date_data['area'], marker='.', s=10, lw=0)\n",
    "    \n",
    "    # set title for each subplot\n",
    "    # axes[i].set_title()\n",
    "    \n",
    "    # set axis limits (will be shared across all subplots)\n",
    "    axes[i].set_ylim(0.1, 60)\n",
    "    axes[i].set_xlim(-3, 131)\n",
    "    \n",
    "    center_idx = n_plots // 2\n",
    "    if i == center_idx:\n",
    "        axes[i].set_ylabel('cross-sectional area between outer channel bank profiles (m²)', labelpad=10)\n",
    "    if i == n_plots - 1:  # last subplot\n",
    "        axes[i].set_xlabel('transect #')\n",
    "    \n",
    "    if i != n_plots - 1:  # not the last subplot\n",
    "        axes[i].tick_params(labelbottom=False)\n",
    "    # if i != center_idx:  # not the center subplot\n",
    "    #     axes[i].tick_params(labelleft=False)\n",
    "\n",
    "    axes[i].annotate(f'{pd.Timestamp(date).date()} to {pd.Timestamp(date2).date()}', xy=(0.12, 0.9), xycoords='axes fraction', \n",
    "        ha='center', va='top', fontsize=7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('transects.pdf', bbox_inches='tight', pad_inches=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dates = alpha_metadata['alphashape_survey_date_1'].unique()\n",
    "n_plots = len(unique_dates)\n",
    "\n",
    "fig, axes = plt.subplots(6, 2, figsize=(21 * centimeters, 5*2 * centimeters), \n",
    "                        sharex=True, sharey=True, \n",
    "                        gridspec_kw={'hspace':0.1, 'wspace':0.1})\n",
    "\n",
    "for i, date in enumerate(unique_dates):\n",
    "    row = i // 2  # integer division: 0,1→0, 2,3→1, 4,5→2, etc.\n",
    "    col = i % 2   # modulo: 0,2,4,6,8→0, 1,3,5,7,9→1\n",
    "    \n",
    "    date_data = alpha_metadata[alpha_metadata['alphashape_survey_date_1'] == date]\n",
    "    date2 = date_data['alphashape_survey_date_2'].iloc[0]\n",
    "    \n",
    "    # plot data using 2D indexing\n",
    "    axes[row, col].scatter(date_data['transect_idx'], date_data['area'], \n",
    "                          marker='.', s=10, lw=0)\n",
    "    \n",
    "    # set axis limits\n",
    "    axes[row, col].set_ylim(0.1, 60)\n",
    "    axes[row, col].set_xlim(-3, 131)\n",
    "    \n",
    "    # ylabel only on left column\n",
    "    # if col == 0:\n",
    "    #     axes[row, col].set_ylabel('cross-sectional area between outer channel bank profiles (m²)', \n",
    "    #                              labelpad=10)\n",
    "    \n",
    "    # xlabel only on bottom row\n",
    "    if row == 4:\n",
    "        axes[row, col].set_xlabel('transect #')\n",
    "    \n",
    "    # hide tick labels except on edges\n",
    "    if row != 4:\n",
    "        axes[row, col].tick_params(labelbottom=False)\n",
    "    # if col == 0:\n",
    "    #     axes[row, col].tick_params(labelleft=False)\n",
    "    # if col == 1:\n",
    "    #     axes[row, col].tick_params(labelleft=False)\n",
    "\n",
    "    axes[row, col].annotate(f'{pd.Timestamp(date).date()} to {pd.Timestamp(date2).date()}', \n",
    "                           xy=(0.2, 0.9), xycoords='axes fraction', \n",
    "                           ha='center', va='top', fontsize=7)\n",
    "\n",
    "for i in range(n_plots, 10):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    axes[row, col].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('transects.pdf', bbox_inches='tight', pad_inches=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102",
   "metadata": {},
   "source": [
    "#### examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_val = 2.5\n",
    "alpha_shape = alphashape.alphashape(points_2d, alpha_val)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 5), dpi=150)\n",
    "ax.scatter(*zip(*points_2d), s=1, marker='.', label='sampled points')\n",
    "\n",
    "x, y = alpha_shape.exterior.xy\n",
    "ax.fill(x, y, alpha=0.2, color='gray', label=f'alpha = {alpha_val}')\n",
    "\n",
    "ax.set(xlabel='x', ylabel='z', title='alpha shape overlay')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([center_points, boundary_points], ignore_index=True)\n",
    "\n",
    "points_2d = list(zip(df_all['x_piecewise'], df_all['z_piecewise']))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(*zip(*points_2d), s=2)\n",
    "ax.set(xlabel='x', ylabel='z', title='points used for alpha shape')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_val = 5\n",
    "alpha_shape = alphashape.alphashape(points_2d, alpha_val)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 5), dpi=150)\n",
    "ax.scatter(*zip(*points_2d), s=1, marker='.', label='sampled points')\n",
    "\n",
    "x, y = alpha_shape.exterior.xy\n",
    "ax.fill(x, y, alpha=0.2, color='gray', label=f'alpha = {alpha_val}')\n",
    "\n",
    "ax.set(xlabel='x', ylabel='z', title='alpha shape overlay')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = alpha_shape.area\n",
    "print(f'Area: {area:.2f} square units')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all z values less than the highest z_min for each transect (combat effect of stage height variation)\n",
    "\n",
    "z_min_max = (\n",
    "    all_transects\n",
    "    .groupby(['transect_idx', 'survey_date'])['z'].min()\n",
    "    .groupby('transect_idx').max()\n",
    "    .rename('z_min_max')\n",
    "    .reset_index()\n",
    ")\n",
    "all_transects = all_transects.merge(z_min_max, on='transect_idx')\n",
    "all_transects = all_transects[all_transects['z'] >= all_transects['z_min_max']].copy()\n",
    "all_transects = all_transects.drop(columns='z_min_max')\n",
    "\n",
    "# adjust d_centerline to be relative to the min value for each transect\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109",
   "metadata": {},
   "source": [
    "plot adjusted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transect_elevation(df, transect_idx=None, survey_date=None, bend=None):\n",
    "    \"\"\"\n",
    "    Plot elevation profiles for a single transect (color by survey_date)\n",
    "    or a single survey_date (color by transect_idx).\n",
    "    Optionally filter by bend when survey_date is specified.\n",
    "    \"\"\"\n",
    "    if (transect_idx is not None) and (survey_date is not None):\n",
    "        raise ValueError(\"Specify only one of transect_idx or survey_date.\")\n",
    "    if (transect_idx is None) and (survey_date is None):\n",
    "        raise ValueError(\"Specify either transect_idx or survey_date.\")\n",
    "\n",
    "    if transect_idx is not None:\n",
    "        subset = df[df['transect_idx'] == transect_idx]\n",
    "        color_col = 'survey_date'\n",
    "        cmap = 'viridis'\n",
    "        label = 'survey'\n",
    "        title = f'transect {transect_idx}'\n",
    "    else:\n",
    "        subset = df[df['survey_date'] == pd.to_datetime(survey_date)]\n",
    "        if bend is not None:\n",
    "            subset = subset[subset['bend'] == bend]\n",
    "        color_col = 'transect_idx'\n",
    "        cmap = 'magma'\n",
    "        label = 'transect number'\n",
    "        title = f'survey on {survey_date}' + (f', bend {bend}' if bend is not None else '')\n",
    "\n",
    "    if color_col == 'survey_date':\n",
    "        color_vals = mdates.date2num(subset[color_col])\n",
    "    else:\n",
    "        color_vals = subset[color_col]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15 * centimeters, 10 * centimeters))\n",
    "\n",
    "    sc = ax.scatter(\n",
    "        x=subset['d_centerline'],\n",
    "        y=subset['z'],\n",
    "        c=color_vals,\n",
    "        cmap=cmap,\n",
    "        alpha=0.5,\n",
    "        marker='o',\n",
    "        s=5,\n",
    "    )\n",
    "    cbar = plt.colorbar(sc, ax=ax, orientation='vertical', pad=0.03, aspect=15, shrink=0.5)\n",
    "    cbar.set_label(label)\n",
    "\n",
    "    if color_col == 'survey_date':\n",
    "        cbar.ax.yaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "\n",
    "    ax.set_xlabel('distance along transect (m)')\n",
    "    ax.set_ylabel('elevation (m)')\n",
    "    ax.set_title(title, fontsize='medium')\n",
    "    # ax.set_aspect('equal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_transect_elevation(all_transects, transect_idx=58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_transect_elevation(all_transects, survey_date='2022-06-17', bend=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113",
   "metadata": {},
   "source": [
    "detour to investigate distribution of erosion values calculated with mean, median, IQR of d_centerline_adj per transect. suspicious from initial plots that point density effects are skewing results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inves\n",
    "\n",
    "group_cols = ['transect_idx', 'survey_date']\n",
    "\n",
    "group_stats = (\n",
    "    all_transects\n",
    "    .groupby(['transect_idx', 'survey_date'])['d_centerline_adj']\n",
    "    .agg(\n",
    "        median='median',\n",
    "        mean='mean',\n",
    "        q25=lambda x: x.quantile(0.25),\n",
    "        q75=lambda x: x.quantile(0.75)\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_with_stats = all_transects.merge(group_stats, on=['transect_idx', 'survey_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": [
    "transect_ids = df_with_stats['transect_idx'].unique()\n",
    "\n",
    "# loop over transects\n",
    "for transect_id in transect_ids[::10]:\n",
    "    subset = df_with_stats[df_with_stats['transect_idx'] == transect_id]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "    ax.scatter(subset['survey_date'], subset['d_centerline_adj'], label='original points', s=8, alpha=0.5)\n",
    "    ax.plot(subset['survey_date'], subset['median'], label='median', color='black', linewidth=1)\n",
    "    ax.plot(subset['survey_date'], subset['mean'], label='mean', color='red', linestyle='--', linewidth=1)\n",
    "\n",
    "    ax.fill_between(\n",
    "        subset['survey_date'],\n",
    "        subset['q25'],\n",
    "        subset['q75'],\n",
    "        color='gray',\n",
    "        alpha=0.2,\n",
    "        label='IQR (25–75p)'\n",
    "    )\n",
    "\n",
    "    ax.set_ylabel('d_centerline_adj (m)')\n",
    "    ax.set_xlabel('survey date')\n",
    "    ax.set_title(f'transect {transect_id}')\n",
    "    ax.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacetime2-alpha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
